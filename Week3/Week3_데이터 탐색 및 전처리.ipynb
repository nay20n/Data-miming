{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Week-3: 데이터 탐색 및 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Pandas 라이브러리 소개**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRSu9xFbA6COOd9Wq-koFEoAFD7wpFgbvdz6Q&s\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2009년 오픈소스로 공개된 이후 데이터 분석 및 가공을 위한 표준 라이브러리로 자리잡음\n",
    "- 데이터프레임을 활용하면 구조화된 데이터의 처리 및 변형이 용이함\n",
    "- 내부적으로 Cython(C++ 기반 최적화 코드)을 사용하여 빠른 속도 제공\n",
    "- 주요 활용 라이브러리:\n",
    "    - 산술 계산: NumPy, SciPy 등등\n",
    "    - 데이터 분석: statsmodels, scikit-learn 등\n",
    "    - 시각화: Matplotlib, Seaborn 등등\n",
    "- Anaconda, Google Colab 등 환경에서는 기본 설치됨, 필요 시 pip install pandas 로 추가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Pandas 현재 버전 확인\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas 현재 버전 확인\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas는 Series(1차원 배열)와 DataFrame(2차원 테이블)을 제공하여 구조화된 데이터 분석을 쉽게 수행할 수 있도록 지원함\n",
    "    - Series: NumPy 배열과 유사하지만 인덱스를 포함하여 더 유연하게 사용 가능\n",
    "    - DataFrame: 엑셀과 같이 행과 열로 구성된 2차원 테이블 구조를 나타내며, 데이터 분석 실무에서 주로 사용됨\n",
    "    - 여러 유형의 데이터를 공통 포맷으로 정리하여 분석 및 처리가 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 시리즈 소개**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시리즈는 데이터가 순차적으로 나열된 1차원 배열 형태의 자료 구조임\n",
    "  - 시리즈는 인덱스(Index)와 데이터 값으로 구성되며, 이러한 구조는 키(Key)-값(Value)의 쌍으로 이루어진 딕셔너리(Dictionary)와 비슷함\n",
    "  - 시리즈의 인덱스는 데이터의 위치뿐 아니라 특정 데이터에 접근하기 위한 식별자(레이블) 역할을 함\n",
    "  - 인덱스는 숫자뿐 아니라 문자열, 날짜 등 다양한 형태로 설정 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tomasbeuzen.com/python-programming-for-data-science/_images/series.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. 시리즈 생성성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Pandas Series 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mSeries(data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1.3\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Pandas Series 생성\n",
    "pd.Series(data = [-5, 1.3, 21, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series 생성 (인덱스 추가)\n",
    "pd.Series(data = [-5, 1.3, 21, 6, 3],\n",
    "          index = ['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series 생성 (딕셔너리 사용)\n",
    "pd.Series(data = {'a': 10, 'b': 20, 'c': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. 시리즈 속성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시리즈의 index 속성을 사용하면 인덱스만 따로 추출할 수 있으며, values 속성을 사용하면 데이터 값만 따로 추출할 수 있음\n",
    "    - 시리즈의 인덱스는 Pandas의 Index 객체로 반환되며, NumPy 배열로 사용하려면 to_numpy()를 이용하여 변환이 필요함\n",
    "    - 데이터 값은 기본적으로 NumPy 배열로 반환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series 생성 (딕셔너리 사용 및 인덱스 추가)\n",
    "series = pd.Series(data = {'a': 10, 'b': 20, 'c': 30})\n",
    "\n",
    "# 인덱스 선택(Index 객체로 반환)\n",
    "index_array = series.index\n",
    "print(index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 배열로 변환\n",
    "index_numpy = series.index.to_numpy()\n",
    "print(index_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 값 추출 (NumPy 배열 형태)\n",
    "values = series.values\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3. 시리즈 인덱싱 및 슬라이싱**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시리즈의 원소를 선택할 때는 데이터의 위치를 나타내는 정수 인덱스(위치 기반) 또는 인덱스 이름(레이블 기반)을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 기반 인덱스로 접근\n",
    "series.iloc[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 이름(레이블)으로 접근\n",
    "series['a'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개 선택할 때\n",
    "series.loc[['a', 'c']]  # 인덱스 이름(레이블)을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개 선택할 때\n",
    "series.iloc[[0, 2]]  # 정수 위치를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 데이터프레임 소개**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임(DataFrame)은 데이터를 행(row)과 열(column)로 구성된 2차원 테이블 구조로 표현한 객체임\n",
    "  - 각 열(column)은 서로 다른 데이터 유형을 가질 수 있으며, 행(row)과 열(column)의 조합으로 데이터를 관리함\n",
    "  - 데이터프레임은 여러 개의 시리즈(Series)가 공통된 인덱스를 기준으로 결합된 형태로 생각할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tomasbeuzen.com/python-programming-for-data-science/_images/dataframe.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. 데이터프레임 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임을 만들기 위해서는 원소의 개수(길이)가 동일한 여러 개의 1차원 배열(리스트 또는 시리즈)이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 길이의 리스트를 값으로 갖는 딕셔너리로 데이터프레임 생성\n",
    "data = {'Name': ['Hong Gil-dong', 'Kim Cheol-soo', 'Lee Young-hee'],\n",
    "    'Age': [25, 30, 28],\n",
    "    'City': ['Seoul', 'Busan', 'Daejeon']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임의 구조적 특성상 2차원 배열 형태의 데이터를 데이터프레임으로 쉽게 변환할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 배열 데이터\n",
    "data = [[10, 20, 30], [40, 50, 60]]\n",
    "\n",
    "# 행 인덱스와 열 이름을 직접 지정하여 데이터프레임 생성\n",
    "df = pd.DataFrame(data, index=['row1', 'row2'], columns=['col1', 'col2', 'col3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 인덱스와 열 이름 확인\n",
    "print(df.index) \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 외부 파일 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas는 CSV, Excel, JSON, SQL, HTML 등 다양한 형식의 외부 파일을 읽어와 데이터프레임으로 변환하는 메서드를 제공함\n",
    "  - 데이터프레임으로 변환된 이후에는 Pandas에서 제공하는 모든 메서드와 기능을 자유롭게 사용할 수 있음\n",
    "  - 반대로, 데이터프레임을 원하는 형식으로 다시 파일로 저장하는 메서드도 제공함(to_csv, to_excel 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **파일 형식**  | **읽기 함수 (`read_*`)** | **저장 함수 (`to_*`)**  |\n",
    "|----------------|--------------------------|-------------------------|\n",
    "| **CSV 파일**   | `read_csv()`             | `to_csv()`              |\n",
    "| **Excel 파일** | `read_excel()`           | `to_excel()`            |\n",
    "| **HTML 파일**  | `read_html()`            | `to_html()`             |\n",
    "| **SQL**        | `read_sql()`             | `to_sql()`              |\n",
    "| **JSON 파일**  | `read_json()`            | `to_json()`             |\n",
    "| **Parquet**    | `read_parquet()`         | `to_parquet()`          |\n",
    "| **HDF5**       | `read_hdf()`             | `to_hdf()`              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. CSV 파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas의 read_csv() 함수에 파일 경로(또는 파일명)를 입력하면 CSV 파일을 읽어 데이터프레임으로 변환함\n",
    "  - header 매개변수는 데이터프레임의 열 이름으로 사용할 행을 지정함(기본값은 첫 번째 행임)\n",
    "  - index_col 매개변수는 데이터프레임에서 행 인덱스로 사용할 열을 지정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 행을 열 이름으로 지정\n",
    "df = pd.read_csv('exam.csv', header=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 열을 행 인덱스로 설정\n",
    "df = pd.read_csv('exam.csv', index_col=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. 데이터 확인하기: head(), tail()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터프레임의 처음 혹은 마지막 n개의 행을 반환\n",
    "    * 기본적으로 5개의 행을 반환하지만, n 값을 입력하면 반환 개수를 조정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 5개 행 출력\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 10개 행 출력\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. 차원 확인: shape()**\n",
    "* 데이터프레임의 차원을 나타내는 튜플을 반환\n",
    "    *  튜플의 첫 번째 요소는 행의 개수를, 두 번째 요소는 열의 개수를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 행과 열의 개수 출력\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4. 요약 정보: info()**\n",
    "* 데이터프레임에 대한 상세한 요약 정보를 제공\n",
    "    * 데이터프레임의 클래스 유형, 행 인덱스의 범위와 각 열의 이름, 각 열의 데이터 유형, 비어 있지 않은 값의 개수, 메모리 사용량 등을 출력\n",
    "    * 대규모 데이터프레임을 활용할 때 데이터의 전반적인 구조와 결측치가 있는지 빠르게 확인할 수 있는 유용한 방법을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  데이터프레임의 상세 정보 출력\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5. 기초통계: describe()**\n",
    "\n",
    "* 데이터프레임의 숫자형 컬럼에 대해 주요 기술 통계 정보를 요약하여 제공\n",
    "    * 평균(mean), 표준편차(std), 최솟값(min), 최댓값(max), 사분위수(25%, 50%, 75%) 등의 통계를 출력\n",
    "    * include='all' 옵션을 사용하면 숫자형이 아닌 열(예: 문자열이나 카테고리형 데이터)에 대한 정보도 포함하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 통계 정보 출력\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.6. 비결측값 개수 계산: count() 함수**\n",
    "* 데이터프레임의 각 컬럼에 대해 비결측값(non-NA/null)의 개수를 계산하여 시리즈 객체로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열의 유효한 데이터 개수 출력\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.7. 고유값 빈도 계산: value_counts()**\n",
    "\n",
    "* 각 고유값이 데이터 내에서 몇 번 나타나는지 보여주며, 기본적으로 내림차순으로 정렬되어 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class' 열의 고유값 개수 출력\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Pandas 주요 기능**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1. 열 이름 수정: rename()**\n",
    "\n",
    "* 데이터프레임의 특정 열 이름을 새로운 이름으로 변경할 수 있음\n",
    "    * columns 매개변수에 딕셔너리 형태로 변경할 열 이름을 전달\n",
    "    * inplace=True를 설정하면 원본 데이터프레임이 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼 이름을 대문자로 변경\n",
    "df.rename(columns={'class': 'CLASS', 'math': 'MATH', 'english': 'ENGLISH', 'science': 'SCIENCE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2. 열 삭제: drop()**\n",
    "\n",
    "* 데이터프레임에서 특정 열을 삭제할 때 사용 → columns 옵션에 삭제할 열 이름을 리스트로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class' 열을 삭제\n",
    "df.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3. 특정 행 선택: loc[] 및 iloc[] 속성**\n",
    "\n",
    "- 인덱스 이름(index label)을 기준으로 행을 선택할 때는 loc[]를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 이름(label)으로 행 선택\n",
    "df.loc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정수 기반 위치 인덱스(integer position-based indexing)를 사용할 때는 iloc[]를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 위치로 행 선택\n",
    "df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2개 이상의 행 인덱스를 리스트 형태로 입력하면 해당하는 모든 행을 동시에 선택할 수 있음\n",
    "  - loc[]은 인덱스 이름(index label) 리스트를 사용하여 여러 행 선택 가능\n",
    "  - iloc[]은 정수형 위치(integer position) 리스트를 사용하여 여러 행 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 이름을 이용해 여러 행 선택\n",
    "df.loc[[1, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수형 위치 인덱스를 이용해 여러 행 선택\n",
    "df.iloc[[0, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 슬라이싱 기법을 사용하여 연속된 행 범위를 선택할 수도 있음\n",
    "  - loc[start:end]: 인덱스 이름(label) 기준으로 슬라이싱하며 끝 인덱스를 포함(inclusive)함\n",
    "  - iloc[start:end]: 정수형 위치(integer position) 기준으로 슬라이싱하며 끝 인덱스를 포함하지 않음(exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[]을 사용한 슬라이싱 (끝 인덱스 포함)\n",
    "df.loc[2:4]  # 인덱스 2~4까지 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[]을 사용한 슬라이싱 (끝 인덱스 미포함)\n",
    "df.iloc[1:4]  # 정수 위치 1~3까지 포함, 위치 4는 제외됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.4. 특정 행 선택: 조건식**\n",
    "\n",
    "- 특정 열의 값을 기준으로 주어진 조건을 만족하는 행을 선택할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class가 1인 행만 선택\n",
    "df[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[]를 사용할 경우\n",
    "df.loc[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 가지 조건을 동시에 만족시켜야 하는 경우 논리 연산자 & (AND)를 사용하고, 하나의 조건만 만족하면 되는 경우 논리 연산자 | (OR)를 사용하여 조건을 결합할 수 있음\n",
    "  - 조건식을 사용할 때는 각 조건을 반드시 ()로 감싸야 함\n",
    "  - Pandas에서는 Python의 and/or 연산자를 사용할 수 없으며, 대신 & (AND), | (OR)를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1반(class == 1) & 수학 점수 >= 50\n",
    "print(df[(df['class'] == 1) & (df['math'] >= 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수학 점수>= 90 | 과학 점수 >= 95\n",
    "print(df[(df['math'] >= 90) | (df['science'] >= 95)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- isin() 함수를 사용하면 특정 열에서 주어진 여러 개의 값 중 하나라도 포함된 행을 선택할 수 있음\n",
    "  - 여러 개의 값을 리스트 형태로 지정하여 해당 값이 포함된 행만 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수학 점수가 80 또는 90점인 행 선택\n",
    "print(df[df['math'].isin([80, 90])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.5. 특정 컬럼 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대괄호([]) 안에 열 이름을 지정하여 데이터프레임에서 특정 열을 선택할 수 있음\n",
    "  - 하나의 열을 선택할 때는 열 이름을 문자열로 입력하면 해당 열이 Series로 반환됨\n",
    "  - 두 개 이상의 열을 선택할 때는 열 이름을 리스트(List) 형태로 입력하면 데이터프레임이 반환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mat' 컬럼 선택 (Series 반환)\n",
    "df['math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'math'과 'science' 열 선택 (DataFrame 반환)\n",
    "df[['math', 'science']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.6. 원소 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임에서 [행, 열] 형식으로 행과 열의 위치 좌표를 입력하면 특정 원소를 선택할 수 있음\n",
    "  - loc[행, 열] → 인덱스 이름(label)과 열 이름(column name)으로 접근\n",
    "  - iloc[행, 열] → 정수형 위치 인덱스(integer position)로 접근\n",
    "  - 반환 형태:\n",
    "    - 1개의 행 + 2개 이상의 열 → Series 반환\n",
    "    - 2개 이상의 행 + 1개의 열 → Series 반환\n",
    "    - 2개 이상의 행 + 2개 이상의 열 → DataFrame 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc을 사용하여 특정 원소 선택\n",
    "df.loc[1, 'math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc을 사용하여 특정 원소 선택\n",
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iat와 at은 Pandas에서 단일 값 (scalar value)에 빠르게 접근하기 위해 사용\n",
    "  - iloc 및 loc에 비해 빠른 속도로 특정 값에 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at을 사용하여 특정 원소 선택 \n",
    "df.at[1, 'math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iat을 사용하여 특정 원소 선택 \n",
    "df.iat[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임에서 2개 이상의 원소를 선택하여 출력할 수도 있음\n",
    " - 여러 개의 행을 선택할 때는 인덱스 배열을 리스트(List) 형태로 입력하거나 슬라이싱 기법을 사용할 수 있음\n",
    " - 선택한 행과 열의 개수에 따라 반환되는 객체가 달라짐:\n",
    "    - 1개의 열을 선택하면 Series 반환\n",
    "    - 2개 이상의 열을 선택하면 DataFrame 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 행 선택 (리스트로 지정) → DataFrame 반환\n",
    "df.loc[[1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 행 선택 (슬라이싱) → DataFrame 반환\n",
    "df.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 행과 특정 열 선택 → Series 반환\n",
    "df.loc[[1, 3], 'math']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 행과 여러 개의 열 선택 → DataFrame 반환\n",
    "df.loc[[1, 3], ['math', 'science']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.7. 파생변수**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새로운 컬럼을 추가하려면 대괄호([]) 안에 새로운 컬럼의 이름을 입력하고 기존 컬럼들을 산술 연산자로 조합하여 계산하면 됨\n",
    "    - 산술 연산자를 활용하여 여러 열의 값을 합산하거나 새로운 계산을 수행할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '총점' 열 추가\n",
    "df['toal'] = df['math'] + df['english'] + df['science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '평균' 열 추가\n",
    "df['average'] = df[['math', 'english', 'science']].mean(axis=1) # 반올림: round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lambda 함수를 apply() 메서드와 함께 사용하면 특정 조건에 따라 새로운 값을 계산하여 파생변수를 추가할 수 있음\n",
    "    - 조건문을 활용하여 데이터 값에 따라 새로운 값을 할당 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 함수를 사용하여 합격 여부 파생변수 추가 (60점 이상 합격)\n",
    "df['result'] = df['math'].apply(lambda x: 'Pass' if x >= 60 else 'Fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 과목 평균을 계산하여 등급 부여\n",
    "df['grade'] = df['average'].apply(lambda x: 'A' if x >= 80 else ('B' if x >= 60 else 'C'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.8. 데이터 정렬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort_values() 함수를 사용하면 특정 열을 기준으로 데이터를 오름차순 또는 내림차순으로 정렬할 수 있음\n",
    "    - 기본적으로 오름차순(ascending=True) 정렬이 수행됨\n",
    "    - 내림차순 정렬을 원하면 ascending=False 옵션을 사용\n",
    "    - 여러 개의 열을 기준으로 정렬할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수학 점수를 기준으로 오름차순 정렬 (기본값)\n",
    "df.sort_values(by='math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수학 점수를 기준으로 오름차순 정렬 (기본값)\n",
    "df.sort_values(by='math', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수학 점수가 동일한 경우, 과학 점수를 기준으로 추가 정렬\n",
    "df.sort_values(by=['math', 'science'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. 범주형 데이터**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연속형 데이터를 그대로 사용하는 것보다 일정한 구간(bin)으로 나누어 분석하는 것이 더 효율적인 경우가 있음\n",
    "    - 연속 변수를 일정한 구간으로 나누고, 각 구간을 범주형 이산 변수로 변환하는 과정을 구간 분할(Binning)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1. 특정 구간 분할: cut() 함수**\n",
    "\n",
    "- Pandas의 cut() 함수를 사용하면 연속형 데이터를 특정 구간으로 나누어 범주형 데이터로 변환할 수 있음\n",
    "    - 균등한 구간(bin)을 직접 지정할 수도 있고 자동으로 지정할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수를 3개의 구간으로 나누어 등급 부여\n",
    "bins = [0, 59, 69, 100]\n",
    "labels = ['C', 'B', 'A']\n",
    "df['grade_cut'] = pd.cut(df['math'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2. 분위수 기반 분할: qcut() 함수**\n",
    "* qcut() 함수는 데이터의 분위수(quantile)를 기준으로 구간을 나누는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 분위수를 기준으로 3개 구간으로 나누기\n",
    "df['grade_qcut'] = pd.qcut(df['math'], q=3, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. 데이터 병합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datacomy.com/data_analysis/pandas/merge/types-of-joins.png\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge() 함수는 특정 열을 기준으로 두 개의 데이터프레임을 병합하는 함수임\n",
    "    - 병합하려는 두 데이터프레임을 merge() 함수에 전달하면 기본적으로 on=None 옵션과 how='inner' 옵션이 적용됨\n",
    "    - on=None 옵션: 두 데이터프레임에 공통으로 존재하는 모든 열을 기준으로 자동 병합\n",
    "    - how='inner' 옵션: 공통 열의 데이터가 양쪽 데이터프레임에 모두 존재하는 경우(교집합)만 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 데이터프레임 생성\n",
    "employees = pd.DataFrame({'id':[1,2,3,4],'name':['Johana','Mike','Patricia','James']})\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 데이터프레임 생성\n",
    "salary = pd.DataFrame({'id':[1,2,3,5],'salary':[120000,100000,130000,90000]})\n",
    "salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.1. 교집합: how='inner'(기본값)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공통되는 id 값만 병합됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datacomy.com/data_analysis/pandas/merge/pandas-merge-inner-2.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(employees, salary, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2. 왼쪽 데이터프레임 기준 병합: how='left'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 왼쪽(df1) 데이터프레임의 모든 행 유지하고 오른쪽(df2)에 없는 값은 NaN으로 채움 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datacomy.com/data_analysis/pandas/merge/pandas-merge-left-2.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(employees, salary, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.3. 오른쪽 데이터프레임 기준 병합: how='right'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오른쪽(df2) 데이터프레임의 모든 행 유지하고 왼쪽(df1)에 없는 값은 NaN으로 채움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datacomy.com/data_analysis/pandas/merge/pandas-merge-right-2.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(employees, salary, on='id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.4. 합집합: how='outer'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 양쪽(df1, df2)에 있는 모든 값을 포함하고 없는 값은 NaN으로 채움 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datacomy.com/data_analysis/pandas/merge/pandas-merge-outer-2.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(employees, salary, on='id',how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
