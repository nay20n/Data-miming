{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Week 7: 머신러닝 회귀와 분류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. 머신러닝 개요 및 주요 범주**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/publication/354960266/figure/fig1/AS:11431281251915131@1718389091562/The-main-types-of-machine-learning-Main-approaches-include-classification-and-regression_W640.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 머신러닝은 데이터로부터 자동으로 패턴을 학습하여 미래를 예측하거나 의사결정을 지원하는 기술임\n",
    "\n",
    "* 문제 유형에 따라 지도 학습, 비지도 학습, 강화 학습의 세 가지 범주로 구분할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 범주                    | 정의                                                  | 응용 사례                                                        | 대표적인 알고리즘                              |\n",
    "|-------------------------|------------------------------------------------------|------------------------------------------------------------|-----------------------------------------------|\n",
    "| **지도 학습 (Supervised Learning)** | 입력과 정답(레이블)을 모두 가진 데이터를 기반으로 학습   | - 가격 예측, 스팸 분류, 질병 진단        | - 회귀: 선형 회귀, 랜덤 포레스트<br>- 분류: 결정 트리, 신경망 |\n",
    "| **비지도 학습 (Unsupervised Learning)** | 레이블 없이 데이터의 구조나 패턴을 학습하는 방식 | - 고객 세분화, 문서 클러스터링 | - 군집화: K-평균, DBSCAN<br>- 차원 축소: PCA, t-SNE        |\n",
    "| **강화 학습 (Reinforcement Learning)** | 환경과의 상호작용을 통해 보상을 받고 최적의 행동을 학습  | - 게임 AI, 자율 주행           | - Q-학습<br>- SARSA <br>- 딥 Q 네트워크(DQN)         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 회귀와 분류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*xs6Jr4iAPvoqszF9JgDWOA.png\" width=\"600\">\n",
    "\n",
    "* 지도 학습(Supervised Learning)은 출력 변수의 유형에 따라 회귀(Regression)와 분류(Classification)로 구분됨\n",
    "\n",
    "* 두 방식의 핵심 차이는 출력 변수의 특성에 있으며, 회귀는 연속적 수치를 예측하고 분류는 범주형 클래스 예측을 수행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 항목 | 회귀 (Regression) | 분류 (Classification) |\n",
    "|------|------------------|------------------------|\n",
    "| **정의** | 연속적인 수치값을 예측하는 모델 | 미리 정의된 범주 중 하나를 예측하는 모델 |\n",
    "| **출력 변수 유형** | 연속형 (실수값, 예: 3.5, 102.1) | 범주형 (클래스, 예: 스팸/비스팸, 고/중/저) |\n",
    "| **예시** | 주택 가격 예측, 차량 가격 예측, 수요량 예측 | 스팸 여부 판별, 질병 진단, 리뷰 유용성 분류 |\n",
    "| **대표 알고리즘** | 선형 회귀, 다중 회귀, 랜덤 포레스트 회귀 | 로지스틱 회귀, SVM, 의사결정 트리, 랜덤 포레스트 분류 |\n",
    "| **평가지표** | MAE (Mean Absolute Error)<br>MSE (Mean Squared Error)<br>RMSE (Root Mean Squared Error)<br>R² (결정계수) | Accuracy (정확도)<br>Precision (정밀도)<br>Recall (재현율)<br>F1-score (정밀도와 재현율의 조화 평균) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 회귀 분석 개요 및 실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-1. 회귀의 정의 및 목적**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*2s6eG20EfKEyu1flqvWUqA.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀(Regression)는 **연속적인 수치형 변수(출력)** 를 예측하는 지도 학습 기법임\n",
    "\n",
    "* 입력 변수(X)와 출력 변수(y) 사이의 관계를 학습하여 새로운 데이터에 대한 값을 추정하는 데 사용됨\n",
    "\n",
    "* 예시:\n",
    "\n",
    "  - 중고차 가격 예측\n",
    "\n",
    "  - 주택 시세 예측\n",
    "\n",
    "  - 날씨 예측 (기온, 강수량 등)\n",
    "\n",
    "* 손실 함수(loss function):  머신러닝 모델이 예측이 얼마나 틀렸는지를 측정하는 수학적 함수로, 모델은 손실함수를 최소화하는 방향으로 학습함\n",
    "\n",
    "* 대부분의 회귀 모델은 MSE 최소화를 목적으로 최적의 계수(가중치)를 찾음 → 경사 하강법(Gradient Descent) 또는 정규방정식(Normal Equation)을 통해 수행됨\n",
    "\n",
    "* 모델 예측 → 손실 계산 → 손실 최소화 방향으로 파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-2. 단순 회귀 vs 다중 회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*UgSLpWRxyvkbEd-eQphP7g.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 종류 | 정의 | 예시 |\n",
    "|------|------|------|\n",
    "| **단순 회귀** | 입력 변수가 1개인 회귀 모델 | 가격 = f(연식) |\n",
    "| **다중 회귀** | 여러 개의 입력 변수로 구성된 회귀 모델 | 가격 = f(연식, 주행거리, 출력, 연료타입 등) |\n",
    "\n",
    "* 본 강의에서는 **다중 회귀**를 중심으로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-3. 통계학적 회귀 vs 머신러닝 회귀**\n",
    "\n",
    "| 비교 항목 | 통계 회귀 | 머신러닝 회귀 |\n",
    "|-----------|-----------|----------------|\n",
    "| **목적** | 변수 간의 관계를 설명 | 예측 성능 향상 |\n",
    "| **접근법** | 가설 검정, p-value 해석 | 데이터 기반 모델 학습 |\n",
    "| **모델 해석** | 해석 가능성 중심 (계수 유의성 등) | 예측 정확도 중심 |\n",
    "| **예시 도구** | `statsmodels` | `scikit-learn`, `xgboost` 등 |\n",
    "\n",
    "* 수업에서는 **`scikit-learn`을 활용한 머신러닝 기반 회귀 실습** 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-4. 회귀 모델 평가 지표**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 지표 | 설명 | 특성 |\n",
    "|------|------|------|\n",
    "| **MAE** (Mean Absolute Error) | 실제값과 예측값의 절대 오차 평균 | 직관적, 이상치에 강함 |\n",
    "| **MSE** (Mean Squared Error) | 제곱 오차의 평균 | 큰 오차에 더 민감 |\n",
    "| **RMSE** (Root Mean Squared Error) | MSE의 제곱근 | 원래 단위로 해석 가능 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀 분석은 모델의 **정확한 예측뿐 아니라, 변수 해석과 인사이트 도출**에 매우 유용함  \n",
    "\n",
    "* 이후 실습에서는 실제 데이터를 활용한 다중 회귀 실습을 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-5. 실습: 온라인 리뷰 유용성 예측**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전자상거래 환경에서 고객의 의사결정에 영향을 주는 리뷰의 유용성을 예측하는 분류 모델 구축 실습\n",
    "\n",
    "* 머신러닝 응용에서 주로 도메인 지식이나 특정 분야의 이해를 바탕으로 데이터에 내재된 중요한 정보를 특성으로 변환하는 특성 추출 접근 방식을 널리 사용함\n",
    "\n",
    "* 실습에서는 사용자 정보, 리뷰 내용 특성, 가독성 지수 등 다양한 특성을 기반으로 유용성 여부를 예측함\n",
    "\n",
    "* 오늘 강의에서는 전자상거래 도메인(Yelp.com)에서 실제 연구(Lee et al. 2021)를 바탕으로 정의된 특성을 활용하여 실습을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 데이터 불러오기 및 구조 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYelp_Largo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('Yelp_Largo.csv')\n",
    "\n",
    "# 데이터 크기 및 변수 확인\n",
    "print(\"데이터 크기:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 특성 추출 및 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단어 수 (Word count)\n",
    "  \n",
    "  * 긴 리뷰일수록 더 많은 정보를 담고 있을 가능성이 높으며, 일반적으로 유용하다고 평가될 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['clean_text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 계정 활성 기간 (Elapsed period of account)\n",
    "  \n",
    "  * 계정을 오랫동안 유지한 사용자는 플랫폼에서 신뢰받는 사용자일 가능성이 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 계정 생성일\n",
    "df['user_since'] = pd.to_datetime(df['yelping_since'])\n",
    "\n",
    "# 리뷰 작성일\n",
    "df['review_date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 월 단위\n",
    "df['account_period'] = (df['review_date'] - df['user_since']).dt.days / 30  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 감성 점수 (Sentiment) & 주관성 (Subjectivity)\n",
    " \n",
    "  * Sentiment: 리뷰가 전반적으로 긍정적인지 부정적인지를 나타냄\n",
    "  \n",
    "  * Subjectivity: 얼마나 개인적 의견 중심의 내용인지 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "df['sentiment'] = df['clean_text'].apply(get_sentiment)\n",
    "df['subjectivity'] = df['clean_text'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가독성 점수 (Readability)\n",
    "\n",
    "  * Flesch–Kincaid 가독성 점수는 문장의 길이, 단어의 복잡도 등을 기반으로 얼마나 읽기 쉬운지를 수치화한 지표임 → 점수가 높을수록 더 쉽게 읽힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textstat\n",
    "\n",
    "import textstat\n",
    "\n",
    "df['readability'] = df['clean_text'].apply(lambda x: textstat.flesch_reading_ease(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최종 특성 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용할 변수\n",
    "selected_columns = ['review_stars', 'word_count', 'number_of_friends', 'account_period','stars', 'business_review_count', 'sentiment', 'subjectivity', 'readability']\n",
    "\n",
    "# X: 입력 변수\n",
    "X = df[selected_columns]\n",
    "\n",
    "# y: 출력 변수 (useful)\n",
    "y = df['useful'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 학습/검증 데이터 분할**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습 80%, 검증 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 특성 표준화**\n",
    "\n",
    " * 스케일이 다른 특성들 간 영향을 균형 있게 맞추기 위해 평균=0, 표준편차=1로 정규화함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 표준화 vs 정규화\n",
    "\n",
    "    * 정규화는 \"값의 범위 조정\", 표준화는 \"분포 조정\"이 핵심!\n",
    "\n",
    "    * 데이터 특성과 이상치 여부에 따라 적절한 방식 선택 필요\n",
    "  \n",
    "\n",
    "\n",
    "| 구분       | 정규화 (Normalization)                           | 표준화 (Standardization)                           |\n",
    "|------------|-------------------------------------------------|---------------------------------------------------|\n",
    "| **정의**   | 데이터 포인트를 0과 1 사이의 범위로 조정  | 평균을 0, 표준편차를 1로 맞춰 분포를 정규화   |\n",
    "| **목적**   | 데이터 값을 특정 범위 내로 제한  | 데이터의 분포를 정규 분포로 변환     |\n",
    "| **수식**   |  $ \\frac{X - \\text{min}(X)}{\\text{max}(X) - \\text{min}(X)} $ | $ \\frac{X - \\mu}{\\sigma} $                    |\n",
    "| **주요 사용** | 범위가 명확한 변수 / 거리 기반 알고리즘 (K-NN, 신경망 등) | 이상치가 있는 경우 / 분포 기반 알고리즘 (SVM, PCA 등) |\n",
    "| **특징**   | - 값이 0~1 사이로 조정됨<br>- 최소/최대값에 민감함 | - 평균=0, 표준편차=1로 변환 <br>- 정규분포 가정 모델에 유리하지만 필수 아님 |\n",
    "| **대표 함수**   | `StandardScaler()` | `MinMaxScaler()` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. 다중 회귀 모델 학습**\n",
    "   \n",
    " * 모든 입력 특성을 동시에 고려하여 useful 값을 예측하는 선형 회귀 모델을 학습함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. 회귀 계수 해석**\n",
    "   \n",
    " * 계수 양수: 해당 특성이 유용성을 높이는 방향으로 영향\n",
    "\n",
    " * 계수 음수: 유용성을 낮추는 방향으로 영향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"회귀 계수:\")\n",
    "display(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. 성능 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 평가 지표\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"회귀 성능 평가 결과:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 분류 분석의 이론과 실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-1. 분류(Classification)의 정의**\n",
    "\n",
    "* 분류는 **출력 변수가 어느 범주(클래스)에 속하는지 예측**하는 지도 학습 방식\n",
    "\n",
    "* 예시:\n",
    "  - 이메일이 스팸인지 아닌지 예측\n",
    "\n",
    "  - 리뷰가 유용한지 아닌지 분류\n",
    "\n",
    "  - 질병 진단 결과(양성/음성) 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lh5.googleusercontent.com/lBQZmzoJqePEXbESJWfnLBkD_dZSOkZBam_HYrpgYPVKx-pRJT_HH5PIIZiIJDSK3Vknnac1Z9rOKSvPjzeL9Ozq5ndqvAyEOkgyPNtVDBC2WBEZKgFbT58i-vjonfdoJP44CoG-GtzvLalgg3XKMEg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-2. 이진 분류 vs 다중 클래스 분류**\n",
    "\n",
    "| 구분 | 이진 분류 (Binary Classification) | 다중 클래스 분류 (Multi-class Classification) |\n",
    "|------|----------------------------------|----------------------------------------------|\n",
    "| **정의** | 두 개의 클래스 중 하나를 예측 | 세 개 이상의 클래스 중 하나를 예측 |\n",
    "| **예시** | 스팸 여부 (스팸/일반) <br> 리뷰 유용성 (유용/비유용) | 뉴스 주제 분류 (정치/스포츠/경제 등) <br> 손글씨 숫자 인식 (0~9) |\n",
    "| **모델 예시** | 로지스틱 회귀, SVM (이진) | 소프트맥스 회귀, 다중 클래스 SVM, 트리 기반 모델 등 |\n",
    "\n",
    "* 본 실습에서는 `이진 분류`를 중심으로 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-3. 로지스틱 회귀 (Logistic Regression)**\n",
    "\n",
    "* 출력값이 이산형(범주형) 인 문제를 해결하기 위한 대표적인 지도학습 알고리즘\n",
    "    \n",
    "    * 입력 특성의 선형 결합을 시그모이드 함수(sigmoid) 로 변환하여 확률로 해석\n",
    "\n",
    "    * 확률을 기준으로 이진 또는 다중 클래스 분류 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tutorialforbeginner.com/images/tutorial/linear-regression-vs-logistic-regression.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시그모이드는 출력값을 0~1로 제한하므로 클래스 1일 확률로 해석 가능\n",
    "\n",
    "* 보통 0.5 기준 → 0.5 이상이면 클래스 1, 미만이면 클래스 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media5.datahacker.rs/2021/01/83-1024x579.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손실함수 : Log Loss (Binary Cross Entropy) 를 사용하여 모델이 예측한 확률값과 실제 라벨 간의 차이를 최소화하며 학습 → 확률 기반으로 잘못된 예측에 더 큰 패널티\n",
    "\n",
    "    $$ \\mathcal{L}(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right] $$\n",
    "\n",
    "    - $y$: 실제 클래스 (0 또는 1)  \n",
    "    - $\\hat{y}$: 모델이 예측한 클래스 1일 확률 (sigmoid 출력)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-4. 분류 성능 평가 지표**\n",
    "\n",
    "|                    | **예측된 클래스: 양성** | **예측된 클래스: 음성** |\n",
    "|--------------------|--------------------------|--------------------------|\n",
    "| **실제 클래스: 양성** | True Positive (TP)      | False Negative (FN)      |\n",
    "| **실제 클래스: 음성** | False Positive (FP)     | True Negative (TN)       |\n",
    "\n",
    "- **True Positive (TP)**: 모델이 양성으로 예측하였고, 실제로도 양성인 경우\n",
    "- **True Negative (TN)**: 모델이 음성으로 예측하였고, 실제로도 음성인 경우\n",
    "- **False Positive (FP)**: 모델이 양성으로 예측하였으나, 실제로는 음성인 경우\n",
    "- **False Negative (FN)**: 모델이 음성으로 예측하였으나, 실제로는 양성인 경우\n",
    "\n",
    "1. **정확도 (Accuracy)**\n",
    "   - 전체 사례(case) 중 정확하게 예측된 사례의 비율\n",
    "\n",
    "   - $ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $\n",
    "\n",
    "2. **정밀도 (Precision)**\n",
    "   - 모델이 양성으로 예측한 사례 중 실제로 양성인 사례의 비율\n",
    "\n",
    "   - $ \\text{Precision} = \\frac{TP}{TP + FP} $\n",
    "\n",
    "3. **재현율 (Recall) 또는 민감도 (Sensitivity)**\n",
    "   - 실제 양성인 사례 중 모델이 양성으로 정확하게 예측한 비율\n",
    "\n",
    "   - $ \\text{Recall} = \\frac{TP}{TP + FN} $\n",
    "\n",
    "4. **F1 점수 (F1 Score)**\n",
    "   - 정밀도와 재현율의 조화 평균\n",
    "   \n",
    "   - $ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실무에서는 **클래스 불균형** 문제가 존재할 수 있으므로 정확도 외에도 Precision, Recall, F1-score 등 다양한 지표를 함께 해석해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-5. 실습: 온라인 리뷰 유용성 분류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 1: 이진 레이블 생성\n",
    "\n",
    "* useful 변수는 해당 리뷰가 얼마나 많은 사람들에게 도움이 되었는지를 나타냅니다. 아래 조건과 같이 apply와 lambda를 활용하여 유용한 리뷰와 유용하지 않는 리뷰를 구분하는 새로운 이진 변수 helpfulness_label을 생성하세요.\n",
    "\n",
    "    * useful >= 1 이면 1 (유용한 리뷰)\n",
    "\n",
    "    * useful == 0 이면 0 (유용하지 않은 리뷰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요\n",
    "df['helpfulness_label'] = de['userful'].apply(lambda x:1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 2: 클래스 불균형 확인\n",
    "\n",
    "* 새로 생성한 helpfulness_label을 기준으로 유용한 리뷰와 유용하지 않은 리뷰의 개수를 출력해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요\n",
    "helpful_review = df[df['helpfulness_label']==1]\n",
    "not_helpful_df=df[df['helpfulness_label']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 3: 클래스 수 균형 맞추기\n",
    "\n",
    "* 머신러닝 모델이 한쪽 클래스에 치우쳐 학습하지 않도록, 두 클래스에서 동일한 개수의 리뷰(5,014개씩) 를 무작위로 추출하세요(random_state=123).\n",
    "\n",
    "* 이후 두 데이터프레임을 하나로 병합(concat)하여 새로운 데이터프레임(balanced_reviews_df)에 저장하고 인덱스를 초기화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요\n",
    "class0 = df[helpful_review].sample(n=5014, random_state=123)\n",
    "class1 = df[unhelpful_review].sample(n=5014, random_state=123)\n",
    "balabced_reviews_df= pd.concat(helpful_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 4: 입력 변수와 출력 변수 지정\n",
    "\n",
    "* 전처리된 balanced_reviews_df 데이터프레임에서 모델에 사용할 입력 변수(X) 와 출력 변수(y) 를 설정하세요.\n",
    "\n",
    "* 입력 변수: review_stars, word_count, number_of_friends, account_period, stars, business_review_count, sentiment, subjectivity, readability\n",
    "\n",
    "* 출력 변수: helpfulness_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 5:  학습/검증 데이터 분할\n",
    "\n",
    "* 전체 데이터를 학습용과 검증용으로 분할하세요 (80% 학습 / 20% 검증). \n",
    "\n",
    "* 클래스 비율이 유지되도록 stratify=y 옵션을 활용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train.y_test = train_test_split(X,y,test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 6: 특성 표준화 (Standardization)\n",
    "\n",
    "* StandardScaler 함수를 이용하여 입력 특성 간 스케일 차이를 보정하기 위해 표준화(Standardization) 를 수행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성하세요\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandeardScaler()\n",
    "\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transfrom(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 7: 로지스틱 회귀 모델 학습\n",
    "\n",
    "* LogisticRegression 함수를 이용해 로지스틱 회귀(Logistic Regression) 모델을 학습하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model=logisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train_scaled,y_train)\n",
    "# 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 8: 학습된 모델을 사용해 검증 세트에서 예측하고 분류 성능(정확도, 정밀도, 재현율, F1-score)을 평가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "x_pred = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "\n",
    "print(\"분류 성능 평가\")\n",
    "print(\"정확도 : {accuracy: .4f}\")\n",
    "# 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 특성 선택(Feature Selection) 기법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 좋은 특성은 좋은 모델을 만든다!\n",
    "  \n",
    "  * 머신러닝 모델의 성능은 대부분 데이터의 품질과 선택된 특성에 크게 의존\n",
    "\n",
    "  * 적절한 특성 선택은 예측 성능, 해석 가능성, 효율성을 향상시킴\n",
    "\n",
    "* 성능 향상: 유용한 특성 선택으로 예측력 향상\n",
    "  \n",
    "* 학습 시간 감소: 불필요한 특성 제거로 훈련 속도 향상\n",
    "\n",
    "* 과적합 방지: 너무 많은 특성 → 과적합 유발 가능성 증가\n",
    "\n",
    "* 해석 용이성: 모델 구조를 이해하기 쉽게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5-1. RFE (Recursive Feature Elimination) – 재귀적 특성 제거**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전체 특성에서 시작 → 영향도가 가장 낮은 특성을 하나씩 제거\n",
    "\n",
    "* 정해진 개수만큼 남을 때까지 반복\n",
    "\n",
    "* 계수 기반이므로 모델 해석과 잘 연결됨\n",
    "\n",
    "* 계산 비용은 높지만, 직관적인 선택 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 기본 분류 모델\n",
    "base_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE로 상위 5개 변수 선택\n",
    "rfe = RFE(base_model, n_features_to_select=5)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 선택된 특성 보기\n",
    "selected_rfe_features = X.columns[rfe.support_]\n",
    "print(\"RFE로 선택된 특성:\")\n",
    "print(selected_rfe_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5-2. Lasso 기반 특성 선택 – L1 정규화 기반 자동 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 학습 중 불필요한 특성의 계수를 0으로 수렴시킴\n",
    "\n",
    "* 자동으로 특성 선택 가능\n",
    "\n",
    "* 특히 희소한(선택된 특성이 적은) 모델 구성에 유리\n",
    "\n",
    "* 단점: 다중공선성에 약하고, L1 penalty가 있는 모델만 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# L1 정규화 기반 Logistic 회귀 (교차검증 포함)\n",
    "lasso_model = LogisticRegressionCV(\n",
    "    penalty='l1', solver='liblinear', cv=5, max_iter=1000\n",
    ")\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Lasso로 중요 변수 자동 선택\n",
    "lasso_selector = SelectFromModel(lasso_model, prefit=True)\n",
    "selected_lasso_features = X.columns[lasso_selector.get_support()]\n",
    "print(\"Lasso 기반 선택된 특성:\")\n",
    "print(selected_lasso_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 특성만 추출\n",
    "X_train_rfe = X_train_scaled[:, rfe.support_]\n",
    "X_test_rfe = X_test_scaled[:, rfe.support_]\n",
    "\n",
    "# 로지스틱 회귀 재학습\n",
    "model_rfe = LogisticRegression(max_iter=1000)\n",
    "model_rfe.fit(X_train_rfe, y_train)\n",
    "\n",
    "# 평가\n",
    "y_pred_rfe = model_rfe.predict(X_test_rfe)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"RFE 기반 모델 성능:\")\n",
    "print(classification_report(y_test, y_pred_rfe, target_names=['Unhelpful', 'Helpful']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5-3. SFS (Sequential Feature Selection) – 순차적 특성 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 성능 기준으로 특성을 하나씩 추가 또는 하나씩 제거\n",
    "\n",
    "* 전방 선택 / 후방 제거 / 단계적 선택 모두 가능\n",
    "\n",
    "    * 전방 선택 (Forward Selection): 가장 성능 좋은 특성을 하나씩 추가\n",
    "\n",
    "    * 후방 소거 (Backward Elimination): 전체 특성에서 중요도 낮은 것부터 제거\n",
    "\n",
    "    * 단계적 선택 (Stepwise Selection): 추가와 제거를 동시에 고려 (floating=True)\n",
    "\n",
    "* 가장 성능 중심적인 접근법\n",
    "\n",
    "* 유연하지만 계산 비용이 큼 (교차검증 병행 시 특히)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전방 선택: 특성을 하나씩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlxtend\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 로지스틱 회귀 모델\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 전방 선택\n",
    "sfs_forward = SFS(log_reg,\n",
    "                  k_features=5, # ← 여기에 선택할 특성 개수 지정\n",
    "                  forward=True,\n",
    "                  floating=False,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 선택된 특성\n",
    "forward_selected_features = list(X.columns[list(sfs_forward.k_feature_idx_)])\n",
    "print(\"전방 선택된 특성:\", forward_selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 후방 제거: 전체 특성에서 하나씩 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후방 소거\n",
    "sfs_backward = SFS(log_reg,\n",
    "                   k_features=(1, X_train.shape[1]), # 1부터 전체 특성 수까지 탐색\n",
    "                   forward=False,\n",
    "                   floating=False,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(X_train_scaled, y_train)\n",
    "\n",
    "backward_selected_features = list(X.columns[list(sfs_backward.k_feature_idx_)])\n",
    "print(\"후방 소거 선택된 특성:\", backward_selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단계적 선택: 추가 및 제거 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계적 선택 (forward=True, floating=True)\n",
    "sfs_stepwise = SFS(log_reg,\n",
    "                   k_features=(1, X_train.shape[1]), # 1부터 전체 특성 수까지 탐색\n",
    "                   forward=True,\n",
    "                   floating=True,  # 추가 + 제거 반복 허용\n",
    "                   scoring='accuracy',\n",
    "                   cv=5,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "sfs_stepwise = sfs_stepwise.fit(X_train_scaled, y_train)\n",
    "\n",
    "stepwise_selected_features = list(X.columns[list(sfs_stepwise.k_feature_idx_)])\n",
    "print(\"단계적 선택된 특성:\", stepwise_selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| 옵션 설정 | 알고리즘 종류 | 의미 |\n",
    "|------------------------------|-------------------------------|------------------------------------------------------------------|\n",
    "| `forward=True, floating=False`  | 전방 선택 (Forward Selection) | 특성을 하나씩 추가하며 더 이상 성능이 개선되지 않으면 종료 → 한 번 추가한 특성은 제거하지 않음 |\n",
    "| `forward=False, floating=False` | 후방 소거 (Backward Elimination) | 모든 특성에서 시작해 성능 향상을 위해 하나씩 제거 → 제거한 특성은 다시 추가하지 않음 |\n",
    "| `forward=True, floating=True`   | 단계적 선택 (Stepwise Selection) | 특성을 추가한 후, 성능 향상이 없는 경우 다시 제거할 수 있음 (즉, 추가 ↔ 제거 반복 가능) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 특성만 사용하여 재학습\n",
    "X_train_selected = X_train_scaled[:, list(sfs_forward.k_feature_idx_)]\n",
    "X_test_selected = X_test_scaled[:, list(sfs_forward.k_feature_idx_)]\n",
    "\n",
    "model_selected = LogisticRegression(max_iter=1000)\n",
    "model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_selected = model_selected.predict(X_test_selected)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5-4. 특성 선택 기법 비교**\n",
    "\n",
    "| 기법   | 방식       | 특징                                | 장점                         | 단점                                  |\n",
    "|--------|------------|-------------------------------------|------------------------------|----------------------------------------|\n",
    "| RFE    | 재귀 제거   | 반복적으로 가장 덜 중요한 특성 제거 | 직관적, 영향도 기반           | 느림, 고비용                           |\n",
    "| Lasso  | L1 규제 기반 | 중요도 낮은 특성의 계수를 0으로 만듦 | 자동 선택, 해석 용이          | 민감도 있음                            |\n",
    "| SFS    | 순차 탐색   | 성능 기준으로 특성 추가/제거         | 다양한 방식, 정확도 기준 선택 | 느림, 변수 간 상호작용 반영 어려움    |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
