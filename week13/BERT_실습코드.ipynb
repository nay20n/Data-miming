{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fcd032",
   "metadata": {},
   "source": [
    "# 1. BERT 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel # 토크나이저와 모델을 불러오기 위한 라이브러리 import\n",
    "import torch # PyTorch 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20889a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 BERT 모델 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # 토크나이저 불러오기\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\") # 모델 불러오기\n",
    "\n",
    "# 추론 모드로 설정 (필수)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장 (예시)\n",
    "text = \"The advancement of natural language processing has significantly improved human-computer interaction, enabling machines to understand context, emotion, and intention more effectively than ever before.\"\n",
    "\n",
    "# 서브워드 문장 (예시)\n",
    "# text = \"The decentralization of decision-making is indispensable in hyperconnected environments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 → Tensor로 변환\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4532f",
   "metadata": {},
   "source": [
    "Inputs IDs (= Token ID)\n",
    "* WordPiece 토큰을 정수 ID로 변환한 결과\n",
    "* Token Embedding\n",
    "* [101]: CLS 토큰\n",
    "* [102]: SEP 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b80d00",
   "metadata": {},
   "source": [
    "token_type_ids\n",
    "* 입력된 각 토큰이 어떤 문장에 속하는지를 표시하는 벡터\n",
    "* Segment Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed792bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66a3b2",
   "metadata": {},
   "source": [
    "attention_mask\n",
    "* 각 토큰이 실제 단어인지(1) 또는 패딩인지(0)를 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_a = \"I love natural language processing.\"\n",
    "text_b = \"It helps computers understand human language.\"\n",
    "\n",
    "inputs_2 = tokenizer(text_a, text_b, return_tensors=\"pt\")\n",
    "print(inputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493267cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 (gradient 계산 X)\n",
    "with torch.no_grad(): # PyTorch에서 “학습이 아닌 추론만 할 때” 사용하는 문법\n",
    "    outputs = model(**inputs) # 토크나이저가 만든 입력을 BERT 모델에 전달하고, 결과를 받는 부분\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038d3dd",
   "metadata": {},
   "source": [
    "last_hidden_state\n",
    "* Tensor [batch_size, sequence_length, hidden_size]\n",
    "* BERT 마지막 층의 출력 벡터 (12층 중 12층 결과)\n",
    "* 각 토큰에 대한 contextual 임베딩\n",
    "* [CLS] 토큰도 여기에 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdef1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 hidden states (마지막 층 기준)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(last_hidden_state.shape)  # (1, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd802a",
   "metadata": {},
   "source": [
    "[CLS] 토큰 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a720309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CLS] 위치의 벡터만 추출 (0번째 토큰)\n",
    "cls_embedding = last_hidden_state[:, 0, :]  # Shape: (1, 768)\n",
    "print(cls_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d01bd",
   "metadata": {},
   "source": [
    "pooler_output\n",
    "* Tensor [batch_size, hidden_size]\n",
    "* [CLS] 벡터에 선형 변환 + tanh 활성화를 적용한 결과\n",
    "* 문장 분류 등에서 간단하게 문장 임베딩으로 사용\n",
    "* [CLS] 벡터와 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 hidden states (마지막 층 기준)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(last_hidden_state.shape)  # (1, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d37946",
   "metadata": {},
   "source": [
    "# 2. BERT 임베딩 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm import tqdm # 진행 상황을 표시하기 위한 라이브러리 import\n",
    "import pandas as pd # 데이터프레임을 사용하기 위한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e74f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Musical_Instruments_2023_sampled.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cls_embedding(text_list):\n",
    "    cls_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(text_list):\n",
    "            # 1. 텍스트 토큰화\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            \n",
    "            # 2. BERT에 입력 → 출력 벡터 얻기\n",
    "            outputs = model(**inputs)\n",
    "            last_hidden = outputs.last_hidden_state  # [1, seq_len, 768]\n",
    "            \n",
    "            # 3. [CLS] 벡터 추출 (첫 번째 토큰 위치)\n",
    "            cls_vector = last_hidden[:, 0, :]  # shape: [1, 768]\n",
    "            \n",
    "            # 4. numpy 변환 및 리스트 저장\n",
    "            cls_embeddings.append(cls_vector.squeeze().numpy())\n",
    "    \n",
    "    return cls_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 실행\n",
    "df['review_bert'] = extract_cls_embedding(df['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e745395",
   "metadata": {},
   "source": [
    "# 3. 예측 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as python_random \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split # 데이터셋을 학습/검증/테스트로 분할하기 위한 라이브러리 import\n",
    "\n",
    "from tensorflow.keras.models import Model # 딥러닝 모델을 구성하기 위한 라이브러리 import\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout # 딥러닝 모델의 레이어를 구성하기 위한 라이브러리 import\n",
    "from tensorflow.keras.optimizers import Adam # 딥러닝 모델의 최적화 알고리즘을 사용하기 위한 라이브러리 import\n",
    "from tensorflow.keras.callbacks import EarlyStopping # 딥러닝 모델의 조기 종료를 위한 콜백 함수 import\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error # 회귀 모델의 성능 평가를 위한 라이브러리 import\n",
    "\n",
    "def reset_random_seeds():\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "reset_random_seeds()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', # 모니터링할 지표\n",
    "    patience=5,         # 해당 에포크 동안 개선되지 않으면 조기 종료\n",
    "    verbose=1,          # 조기 종료 시 메시지 출력\n",
    "    mode='auto',         # 모니터링할 지표의 개선 방향 설정(예측: min, 분류: max)\n",
    "    restore_best_weights=True   # 최적 가중치 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8eb265",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd020d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df_sample):\n",
    "    df_train, df_test = train_test_split(df_sample, # 분할할 데이터셋\n",
    "                                        test_size=0.2, # 테스트 데이터 비율\n",
    "                                        random_state=42) # 랜덤 시드 설정\n",
    "\n",
    "    train_bert = np.array(df_train['review_bert'].tolist()) # BERT 임베딩을 리스트로 변환\n",
    "    y_train = np.array(df_train['rating']) # 평점 데이터를 NumPy 배열로 변환\n",
    "\n",
    "    test_bert = np.array(df_test['review_bert'].tolist())\n",
    "    y_test = np.array(df_test['rating'])\n",
    "\n",
    "    return train_bert, test_bert, y_train, y_test\n",
    "\n",
    "train_bert, test_bert, y_train, y_test = data_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae804f",
   "metadata": {},
   "source": [
    "## 예측 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rating_Predictor(learning_rate, dropout_rate):\n",
    "# 1. Input\n",
    "\n",
    "    bert_input = Input(shape=(768,), name='Review_BERT_Input') # BERT 임베딩 입력 레이어\n",
    "\n",
    "    prediction = Dense(units=128, activation='relu', name='Pradiction_Layer_1')(bert_input) # 첫 번째 은닉층\n",
    "    prediction = Dropout(rate=dropout_rate)(prediction) # 드롭아웃 레이어 추가\n",
    "    prediction = Dense(units=64, activation='relu', name='Pradiction_Layer_2')(prediction) # 두 번째 은닉층\n",
    "    prediction = Dropout(rate=dropout_rate)(prediction)\n",
    "    prediction = Dense(units=32, activation='relu', name='Pradiction_Layer_3')(prediction) # 세 번째 은닉층\n",
    "    prediction = Dropout(rate=dropout_rate)(prediction)\n",
    "\n",
    "    prediction = Dense(1, activation='linear', name='Final_Layer')(prediction) # 최종 출력 레이어 (회귀용)\n",
    "\n",
    "    # Model Definition\n",
    "    model = Model(inputs=[bert_input], outputs=prediction) # 딥러닝 모델 정의\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mean_absolute_error', 'mean_squared_error']) # 모델 컴파일\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b76955",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 # 학습률 설정\n",
    "batch_size = 32 # 배치 크기 설정\n",
    "dropout_rate = 0.0 # 드롭아웃 비율 설정\n",
    "\n",
    "model = Rating_Predictor(learning_rate, dropout_rate) # 딥러닝 모델 생성\n",
    "model.summary() # 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c8c10",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78779d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([train_bert], y_train, # 모델 학습\n",
    "        validation_split=0.125, # 검증 데이터 비율\n",
    "        epochs=100,  # 에포크 수\n",
    "        batch_size=batch_size, # 배치 크기\n",
    "        callbacks=[early_stopping])  # 조기 종료 콜백 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528eacea",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = model.predict([test_bert]) # 모델 예측\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344e8c1",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d68f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_temp = mean_absolute_error(y_test, predicted_ratings) # MAE 계산\n",
    "MSE_temp = mean_squared_error(y_test, predicted_ratings) # MSE 계산\n",
    "RMSE_temp = np.sqrt(MSE_temp) # RMSE 계산\n",
    "MAPE_temp = 100 * mean_absolute_percentage_error(y_test, predicted_ratings) # MAPE 계산\n",
    "\n",
    "print(f'{MAE_temp:.4f}')\n",
    "print(f'{MSE_temp:.4f}')\n",
    "print(f'{RMSE_temp:.4f}')\n",
    "print(f'{MAPE_temp:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hansung_0528",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
